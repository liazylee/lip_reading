{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 19:59:43.493596: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-22 19:59:43.519278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 19:59:43.519298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 19:59:43.520229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 19:59:43.524939: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 19:59:43.964704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "import cv2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T19:59:44.510237659Z",
     "start_time": "2024-02-22T19:59:43.305807310Z"
    }
   },
   "id": "84c5b54e97f1c7c1",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 19:59:44.567511: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.590488: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.590632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T19:59:44.598773605Z",
     "start_time": "2024-02-22T19:59:44.593731620Z"
    }
   },
   "id": "8dd3ca63db55736d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]:\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()  # close the video file\n",
    "\n",
    "    mean = tf.math.reduce_mean(frames)  # compute the mean\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32)) # compute the standard \n",
    "    return tf.cast((frames - mean), tf.float32) / std # normalize to zero mean and "
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T19:59:44.599211920Z",
     "start_time": "2024-02-22T19:59:44.596265872Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' '] (size =28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 19:59:44.609492: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.609636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.609732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.667585: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.667713: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.667818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 19:59:44.667899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14414 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz \"]\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T19:59:44.693111127Z",
     "start_time": "2024-02-22T19:59:44.600469506Z"
    }
   },
   "id": "a9ad48af8c9b8c3a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 19:59:46.158268: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "[mpeg1video @ 0x557123865240] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x557123865240] Warning MVs not available\n"
     ]
    }
   ],
   "source": [
    "def load_alignments(path:str) ->  List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        alignments = f.readlines()\n",
    "    tokens =[]\n",
    "    for line in alignments:\n",
    "        line = line.split()\n",
    "        if line[2] !='sil':\n",
    "            tokens=[*tokens,' ', line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:] \n",
    "def init_alignments(path:str) -> dict[str:List[str]]: \n",
    "    alignments = {}\n",
    "    if not os.path.exists(path): \n",
    "        raise FileNotFoundError(f'{path} does not exist')\n",
    "    for file in os.listdir(path): \n",
    "        if file.endswith('.align'): \n",
    "            with open(os.path.join(path, file), 'r') as f: \n",
    "                lines = f.readlines()\n",
    "            tokens = []\n",
    "            for line in lines:\n",
    "                line = line.split()\n",
    "                if line[2] != 'sil': \n",
    "                    tokens = [*tokens,' ',line[2]]\n",
    "            alignments[file] = char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]\n",
    "    return alignments\n",
    "alignments_dict = init_alignments('./data/alignments/s1')\n",
    "def generate_video_dict(path:str) -> dict[str:List[float]]: \n",
    "    video_dict= {}\n",
    "    if not os.path.exists(path): \n",
    "        raise FileNotFoundError(f'{path} does not exist')\n",
    "    for file in os.listdir(path): \n",
    "        if file.endswith('.mpg'): \n",
    "            cap = cv2.VideoCapture(os.path.join(path, file))\n",
    "            frames = []\n",
    "            for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):  \n",
    "                ret, frame = cap.read()\n",
    "                frame = tf.image.rgb_to_grayscale(frame)\n",
    "                # frames.append(frame[190:236,80:220,:]) # s1\n",
    "                frames.append(frame[200:246,100:240,:]) # s10\n",
    "            cap.release()\n",
    "            mean = tf.math.reduce_mean(frames)\n",
    "            std = tf.math.reduce_std(tf.cast(frames, tf.float16))\n",
    "            video_dict[file] = tf.cast((frames - mean), tf.float16) / std\n",
    "    return video_dict\n",
    "video_dict = generate_video_dict('./data/s1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:00:53.655376824Z",
     "start_time": "2024-02-22T19:59:44.696862996Z"
    }
   },
   "id": "590f88574458bd0c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def load_data(path:str):\n",
    "#     file_name = path.split('/')[-1].split('.')[0]\n",
    "#     video_path=os.path.join('data','s1',f'{file_name}.mpg')\n",
    "#     alignment_path=os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "#     frames=load_video(video_path)\n",
    "#     alignments=load_alignments(alignment_path)\n",
    "#     return frames, alignments\n",
    "def load_data(path: str): \n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    video_path = f'{file_name}.mpg'\n",
    "    alignment_path = f'{file_name}.align'\n",
    "    frames = video_dict.get(video_path)\n",
    "    alignments = alignments_dict.get(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:07:21.332116063Z",
     "start_time": "2024-02-22T20:07:21.290861378Z"
    }
   },
   "id": "9005cf9c544a81ec",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin blue by m zero now\n"
     ]
    }
   ],
   "source": [
    "test_path = './data/s1/bbbmzn.mpg'\n",
    "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('/')[-1].split('.')[0] \n",
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))\n",
    "print(tf.strings.reduce_join(num_to_char(alignments)).numpy().decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:07:28.094759942Z",
     "start_time": "2024-02-22T20:07:28.092793172Z"
    }
   },
   "id": "2a530dc9d2e624aa",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa5c48a5510>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.imshow(frames[12])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:07:35.566356510Z",
     "start_time": "2024-02-22T20:07:35.504816651Z"
    }
   },
   "id": "24315edc7c9f37c1",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float16, tf.int64)) # py_function is used to convert a python function to a tensorflow function\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:03.728195155Z",
     "start_time": "2024-02-22T20:08:03.685824458Z"
    }
   },
   "id": "12573322feb29236",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')  # list all the files\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)   \n",
    "data = data.map(mappable_function) # 75 frames, 46x140 pixels, 1 channel\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40])) # 75 frames, 46x140 pixels, 1 channel\n",
    "data = data.prefetch(tf.data.AUTOTUNE) # prefetch the data\n",
    "# Added for split \n",
    "train = data.take(450) \n",
    "test = data.skip(450)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:04.178765556Z",
     "start_time": "2024-02-22T20:08:04.154988412Z"
    }
   },
   "id": "417a666e73f0e00",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications import ResNet50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:04.705811723Z",
     "start_time": "2024-02-22T20:08:04.704063938Z"
    }
   },
   "id": "3b4130c1b422fdbb",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet',\n",
    "                      include_top=False, input_shape=(46,140, 3))\n",
    "\n",
    "# If you wish to Freeze layers\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = True\n",
    "  \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))  # 128 filters, 3x3 kernel input shape is 75 frames, 46x140 pixels, 1 channel \n",
    "model.add(Activation('relu'))  # activation function\n",
    "model.add(MaxPool3D((1,2,2)))  # max pooling\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))  # 256 filters, 3x3 kernel\n",
    "model.add(Activation('relu'))  \n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))  # flatten the output of the previous layer\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))  # bidirectional LSTM\n",
    "model.add(Dropout(.5))  # dropout layer\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))  # output layer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:07.134654376Z",
     "start_time": "2024-02-22T20:08:05.403513257Z"
    }
   },
   "id": "5f4623daafc388f5",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_6 (Conv3D)           (None, 75, 46, 140, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 75, 46, 140, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPoolin  (None, 75, 23, 70, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 75, 6375)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 75, 256)           6660096   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 75, 29)            7453      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8468840 (32.31 MB)\n",
      "Trainable params: 8468840 (32.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:07.151584842Z",
     "start_time": "2024-02-22T20:08:07.135349506Z"
    }
   },
   "id": "daac226b653c0a37",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "frames, alignments = data.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:08.451188572Z",
     "start_time": "2024-02-22T20:08:08.440179858Z"
    }
   },
   "id": "f63ce407ac8dd1d6",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 20:08:14.899404: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-02-22 20:08:15.080018: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "yhat=model.predict(frames)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:18.813122412Z",
     "start_time": "2024-02-22T20:08:14.256544210Z"
    }
   },
   "id": "3eb565ac2f304cda",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'sssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssdddd'>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:08:57.644236088Z",
     "start_time": "2024-02-22T20:08:57.596565099Z"
    }
   },
   "id": "f3be6d2c197140ca",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):   # learning rate scheduler\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:07.986154368Z",
     "start_time": "2024-02-22T20:11:07.978309778Z"
    }
   },
   "id": "2ba3a510fbef8274",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:08.461960200Z",
     "start_time": "2024-02-22T20:11:08.458130006Z"
    }
   },
   "id": "1c32fbeb41eb76c2",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:09.270826486Z",
     "start_time": "2024-02-22T20:11:09.251938062Z"
    }
   },
   "id": "26e1a6c1abec1387",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models_6','checkpoint'), monitor='loss', save_weights_only=True) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:09.800286396Z",
     "start_time": "2024-02-22T20:11:09.797470042Z"
    }
   },
   "id": "60a7674123ae80a4",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:10.224294589Z",
     "start_time": "2024-02-22T20:11:10.216137418Z"
    }
   },
   "id": "bc77ce4660b9b61c",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 20:11:16.401957: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa5d8acc2f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-22 20:11:16.401972: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2024-02-22 20:11:16.410164: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708632676.462114   32074 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschedule_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    901\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    902\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[0;32m--> 905\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    909\u001B[0m   bound_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\n\u001B[1;32m    910\u001B[0m       \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds\n\u001B[1;32m    911\u001B[0m   )\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/jobs/venv_python/lip_reading/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train, validation_data=test, epochs=60, callbacks=[checkpoint_callback, schedule_callback],batch_size=400)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:11:21.233465291Z",
     "start_time": "2024-02-22T20:11:10.648194167Z"
    }
   },
   "id": "794941b88f658f9c",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_history = model.history.history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T20:11:21.234160827Z"
    }
   },
   "id": "1fd8a20aeca95070"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# draw the loss curve\n",
    "print(loss_history.keys())\n",
    "plt.plot(loss_history['loss'], label='loss')\n",
    "plt.plot(loss_history['val_loss'], label='val_loss')\n",
    "# x label and y label\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.title('Loss Curve for adding resNet50 with datasetS10')\n",
    "plt.legend(loc='upper right')\n",
    "filename = 'loss_curve_resNet50_datasetS10_notitle.png'\n",
    "plt.savefig(filename)      \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6cf1118358ac26e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa5ac7c3580>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models_4/checkpoint')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:13:35.752207998Z",
     "start_time": "2024-02-22T20:13:35.700906356Z"
    }
   },
   "id": "3deede8678fcc67d",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 3s 54ms/step - loss: 87.9974\n",
      " adding resNet50 for dataset S10 The Test loss: 87.99738311767578\n",
      " adding resNet50 for dataset S10 The Test accuracy: 12.002616882324219\n",
      "450/450 [==============================] - 24s 54ms/step - loss: 94.1937\n",
      " adding resNet50 for dataset S10 The Train loss: 94.19366455078125\n"
     ]
    }
   ],
   "source": [
    "test_loss= model.evaluate(test)\n",
    "print(f' adding resNet50 for dataset S10 The Test loss: {test_loss}')\n",
    "# accuracy\n",
    "accuracy = 100 - test_loss\n",
    "print(f' adding resNet50 for dataset S10 The Test accuracy: {accuracy}')\n",
    "# test on the train data\n",
    "train_loss= model.evaluate(train)\n",
    "print(f' adding resNet50 for dataset S10 The Train loss: {train_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:13:33.191404990Z",
     "start_time": "2024-02-22T20:13:05.803407496Z"
    }
   },
   "id": "2d6eff343f77e4e2",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:03.912142741Z",
     "start_time": "2024-02-22T20:16:03.904080343Z"
    }
   },
   "id": "4a8f888782bc0a07",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample = test_data.next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:04.888249349Z",
     "start_time": "2024-02-22T20:16:04.651957808Z"
    }
   },
   "id": "d5d886f61c247bab",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(sample[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:05.717998260Z",
     "start_time": "2024-02-22T20:16:05.631125598Z"
    }
   },
   "id": "1869bb99e4471611",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(), dtype=string, numpy=b'set green by p six please'>,\n <tf.Tensor: shape=(), dtype=string, numpy=b'lay blue with r four please'>]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:08.107223596Z",
     "start_time": "2024-02-22T20:16:08.082388684Z"
    }
   },
   "id": "9915326a1579c880",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:10.641711776Z",
     "start_time": "2024-02-22T20:16:10.638283185Z"
    }
   },
   "id": "ea9a4d4ca77c1877",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(), dtype=string, numpy=b'set gre in eihe soon'>,\n <tf.Tensor: shape=(), dtype=string, numpy=b'set bre wit eiwh soon'>]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T20:16:11.348438019Z",
     "start_time": "2024-02-22T20:16:11.298490715Z"
    }
   },
   "id": "dc949cdd456e51bd",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "39a3bb0d9de98a63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
